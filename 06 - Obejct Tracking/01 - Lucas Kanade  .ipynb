{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72a6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1811ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function goodFeaturesToTrack:\n",
      "\n",
      "goodFeaturesToTrack(...)\n",
      "    goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]]) -> corners\n",
      "    .   @brief Determines strong corners on an image.\n",
      "    .   \n",
      "    .   The function finds the most prominent corners in the image or in the specified image region, as\n",
      "    .   described in @cite Shi94\n",
      "    .   \n",
      "    .   -   Function calculates the corner quality measure at every source image pixel using the\n",
      "    .       #cornerMinEigenVal or #cornerHarris .\n",
      "    .   -   Function performs a non-maximum suppression (the local maximums in *3 x 3* neighborhood are\n",
      "    .       retained).\n",
      "    .   -   The corners with the minimal eigenvalue less than\n",
      "    .       \\f$\\texttt{qualityLevel} \\cdot \\max_{x,y} qualityMeasureMap(x,y)\\f$ are rejected.\n",
      "    .   -   The remaining corners are sorted by the quality measure in the descending order.\n",
      "    .   -   Function throws away each corner for which there is a stronger corner at a distance less than\n",
      "    .       maxDistance.\n",
      "    .   \n",
      "    .   The function can be used to initialize a point-based tracker of an object.\n",
      "    .   \n",
      "    .   @note If the function is called with different values A and B of the parameter qualityLevel , and\n",
      "    .   A \\> B, the vector of returned corners with qualityLevel=A will be the prefix of the output vector\n",
      "    .   with qualityLevel=B .\n",
      "    .   \n",
      "    .   @param image Input 8-bit or floating-point 32-bit, single-channel image.\n",
      "    .   @param corners Output vector of detected corners.\n",
      "    .   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n",
      "    .   the strongest of them is returned. `maxCorners <= 0` implies that no limit on the maximum is set\n",
      "    .   and all detected corners are returned.\n",
      "    .   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\n",
      "    .   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\n",
      "    .   (see #cornerMinEigenVal ) or the Harris function response (see #cornerHarris ). The corners with the\n",
      "    .   quality measure less than the product are rejected. For example, if the best corner has the\n",
      "    .   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\n",
      "    .   less than 15 are rejected.\n",
      "    .   @param minDistance Minimum possible Euclidean distance between the returned corners.\n",
      "    .   @param mask Optional region of interest. If the image is not empty (it needs to have the type\n",
      "    .   CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\n",
      "    .   @param blockSize Size of an average block for computing a derivative covariation matrix over each\n",
      "    .   pixel neighborhood. See cornerEigenValsAndVecs .\n",
      "    .   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see #cornerHarris)\n",
      "    .   or #cornerMinEigenVal.\n",
      "    .   @param k Free parameter of the Harris detector.\n",
      "    .   \n",
      "    .   @sa  cornerMinEigenVal, cornerHarris, calcOpticalFlowPyrLK, estimateRigidTransform,\n",
      "    \n",
      "    \n",
      "    \n",
      "    goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize[, corners[, useHarrisDetector[, k]]]) -> corners\n",
      "    .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.goodFeaturesToTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce74a132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function calcOpticalFlowPyrLK:\n",
      "\n",
      "calcOpticalFlowPyrLK(...)\n",
      "    calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts[, status[, err[, winSize[, maxLevel[, criteria[, flags[, minEigThreshold]]]]]]]) -> nextPts, status, err\n",
      "    .   @brief Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with\n",
      "    .   pyramids.\n",
      "    .   \n",
      "    .   @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.\n",
      "    .   @param nextImg second input image or pyramid of the same size and the same type as prevImg.\n",
      "    .   @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be\n",
      "    .   single-precision floating-point numbers.\n",
      "    .   @param nextPts output vector of 2D points (with single-precision floating-point coordinates)\n",
      "    .   containing the calculated new positions of input features in the second image; when\n",
      "    .   OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.\n",
      "    .   @param status output status vector (of unsigned chars); each element of the vector is set to 1 if\n",
      "    .   the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
      "    .   @param err output vector of errors; each element of the vector is set to an error for the\n",
      "    .   corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't\n",
      "    .   found then the error is not defined (use the status parameter to find such cases).\n",
      "    .   @param winSize size of the search window at each pyramid level.\n",
      "    .   @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single\n",
      "    .   level), if set to 1, two levels are used, and so on; if pyramids are passed to input then\n",
      "    .   algorithm will use as many levels as pyramids have but no more than maxLevel.\n",
      "    .   @param criteria parameter, specifying the termination criteria of the iterative search algorithm\n",
      "    .   (after the specified maximum number of iterations criteria.maxCount or when the search window\n",
      "    .   moves by less than criteria.epsilon.\n",
      "    .   @param flags operation flags:\n",
      "    .    -   **OPTFLOW_USE_INITIAL_FLOW** uses initial estimations, stored in nextPts; if the flag is\n",
      "    .        not set, then prevPts is copied to nextPts and is considered the initial estimate.\n",
      "    .    -   **OPTFLOW_LK_GET_MIN_EIGENVALS** use minimum eigen values as an error measure (see\n",
      "    .        minEigThreshold description); if the flag is not set, then L1 distance between patches\n",
      "    .        around the original and a moved point, divided by number of pixels in a window, is used as a\n",
      "    .        error measure.\n",
      "    .   @param minEigThreshold the algorithm calculates the minimum eigen value of a 2x2 normal matrix of\n",
      "    .   optical flow equations (this matrix is called a spatial gradient matrix in @cite Bouguet00), divided\n",
      "    .   by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding\n",
      "    .   feature is filtered out and its flow is not processed, so it allows to remove bad points and get a\n",
      "    .   performance boost.\n",
      "    .   \n",
      "    .   The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See\n",
      "    .   @cite Bouguet00 . The function is parallelized with the TBB library.\n",
      "    .   \n",
      "    .   @note\n",
      "    .   \n",
      "    .   -   An example using the Lucas-Kanade optical flow algorithm can be found at\n",
      "    .       opencv_source_code/samples/cpp/lkdemo.cpp\n",
      "    .   -   (Python) An example using the Lucas-Kanade optical flow algorithm can be found at\n",
      "    .       opencv_source_code/samples/python/lk_track.py\n",
      "    .   -   (Python) An example using the Lucas-Kanade tracker for homography matching can be found at\n",
      "    .       opencv_source_code/samples/python/lk_homography.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.calcOpticalFlowPyrLK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08bffd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Frame\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "corner_track_param = dict(maxCorners = 10, \n",
    "                          qualityLevel = 0.2, \n",
    "                          minDistance = 10, \n",
    "                          blockSize = 7)\n",
    "\n",
    "lk_param = dict(winSize = (200, 200), \n",
    "                maxLevel = 2, \n",
    "                criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\Data\\computer vision\\video\\Slow Traffic Small Open CV.mp4')\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask =None, **corner_track_param)\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print('Not Frame')\n",
    "        break\n",
    "    next_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, next_gray,prevPts, None, **lk_param)\n",
    "   \n",
    "    \n",
    "    \n",
    "    good_new = nextPts[status ==1]\n",
    "    good_prev = prevPts[status ==1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,(new, prev) in enumerate(zip(good_new, good_prev)):\n",
    "        x_new, y_new = np.intp(new.ravel())\n",
    "        x_prev, y_prev = np.intp(prev.ravel())\n",
    "        \n",
    "        mask = cv2.line(mask, (x_new, y_new), (x_prev, y_prev), color[i].tolist(), 4)\n",
    "        frame = cv2.circle(frame, (x_new, y_new), 6, color[i].tolist(), -1)\n",
    "        \n",
    "        img = cv2.add(mask , frame)\n",
    "        cv2.imshow('frame', img)\n",
    "        \n",
    "        k = cv2.waitKey(10) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "            \n",
    "        prev_gray = next_gray.copy()\n",
    "        prevPts = good_new.reshape(-1,1,2)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97466940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
